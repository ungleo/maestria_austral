{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import urllib3\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import json\n",
    "warnings.simplefilter(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "\n",
    "#AÃ±os a extraer\n",
    "w_anio_dde = 2017\n",
    "w_anio_hta = 2017\n",
    "\n",
    "#meses a extraer\n",
    "w_mes_dde = 1\n",
    "w_mes_hta = 12\n",
    "\n",
    "#paginas de resultados\n",
    "pagina_dde = 1\n",
    "pagina_hta = 20\n",
    "\n",
    "#factor para saltear paginas de resultados para no llevarse solo lo de ppio de mes...\n",
    "cada_n_paginas = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "search_pages = [#[\"https://buscar.lanacion.com.ar/economia/c-Econom%C3%ADa/date-\",\"ECO\"],\n",
    "                #[\"https://buscar.lanacion.com.ar/politica/c-Pol%C3%ADtica/date-\",\"POL\"],\n",
    "                [\"https://buscar.lanacion.com.ar/turismo/c-Turismo/date-\",\"TUR\"]]\n",
    "\n",
    "\n",
    "\n",
    "search_page = \"https://buscar.lanacion.com.ar/Opinion/sort-old/date-\"\n",
    "urls = []\n",
    "for search_class in search_pages:\n",
    "    search_page = search_class[0]\n",
    "    clase = search_class[1]\n",
    "  #  for year in range(w_anio_dde,w_anio_hta+1):   #1997 a 2018\n",
    "    year = 2018    \n",
    "    for month in range(w_mes_dde,w_mes_hta+1):     #1 a 13\n",
    "        for rpage in range(pagina_dde,pagina_hta):   # 1 a 4\n",
    "            try:\n",
    "                page = http.request('GET', search_page+str(year)+str(month).zfill(2)+\"01,\"+\n",
    "                                    str(year)+str(month).zfill(2)+\"28/sort-old/page-\"+\n",
    "                                    str(rpage*cada_n_paginas))\n",
    "                soup = bs4.BeautifulSoup(page.data, \"html.parser\")\n",
    "                first = soup.find(\"li\", {\"class\": \"floatFix notas\"})\n",
    "                urls.append([first.a[\"href\"],clase])\n",
    "                nsib = first.findNextSibling()\n",
    "                print(year,month, rpage,len(urls),\" \", flush=True)\n",
    "                while not nsib is None:\n",
    "                    urls.append([nsib.a[\"href\"],clase])\n",
    "                    nsib = nsib.findNextSibling()\n",
    "            except:\n",
    "                print(\"skipped\", year, month, rpage,clase, search_page+str(year)+str(month).zfill(2)+\"01,\"+\n",
    "                                    str(year)+str(month).zfill(2)+\"28/sort-old/page-\"+\n",
    "                                    str(rpage*cada_n_paginas))\n",
    "                continue\n",
    "        pd.DataFrame(urls).to_csv(\"./validacion_tp/lanacion_valid_url2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_csv(\"./validacion_tp/lanacion_valid_url2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prev_items = pd.read_csv(\"./TP1_articulos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(prev_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped = 0\n",
    "urls = pd.read_csv(\"./validacion_tp/lanacion_valid_url2.csv\")\n",
    "news_items = []\n",
    "for ind,url in urls.iterrows():\n",
    "    if ind > 0:\n",
    "        page = http.request('GET', url[1])\n",
    "        soup = bs4.BeautifulSoup(page.data, \"html.parser\")\n",
    "        try:\n",
    "            titulo1 = soup.find(\"h1\", {\"class\": \"titulo\"}).text\n",
    "            metadatos = json.loads(soup.find('script', type='application/ld+json').text)\n",
    "            titulo = metadatos[\"headline\"], \n",
    "            seccion = metadatos[\"articleSection\"]\n",
    "            fecha = metadatos[\"dateCreated\"]\n",
    "            autor = metadatos[\"creator\"]\n",
    "            tags = metadatos[\"keywords\"]\n",
    "            first = soup.find(\"p\", {\"class\": \"capital\"})\n",
    "            nsib = first.findNextSibling()\n",
    "            article = first.string\n",
    "            if article is None: article = first.text\n",
    "            while not nsib is None:\n",
    "                if not nsib.string is None:\n",
    "                    article = article + nsib.string\n",
    "                nsib = nsib.findNextSibling()\n",
    "            news_items.append([url[1],titulo1, titulo, seccion, fecha, autor, tags, article])\n",
    "            if (ind/1 == int(ind/1)): \n",
    "                print(ind, titulo1, titulo, seccion, fecha, autor, tags,url[1])\n",
    "                pd.DataFrame(news_items, columns = [\"url\",\"titulo1\", \"titulo\", \"seccion\", \"fecha\", \"autor\", \"tags\", \"texto\"]).to_csv(\"./validacion_tp/validacion_lanacion2.csv\", index_label = \"ID\")\n",
    "        except:\n",
    "            skipped +=1\n",
    "            print(\"Skipped ALL: \",skipped, url[1] )\n",
    "            continue   \n",
    "pd.DataFrame(news_items,columns = [\"url\",\"titulo1\", \"titulo\", \"seccion\", \"fecha\", \"autor\", \"tags\", \"texto\"]).to_csv(\"./validacion_tp/validacion_lanacion2.csv\", index_label = \"ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
